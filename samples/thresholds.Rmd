---
title: "Time-Varying Thresholds for Alert Generation"
date: "December 14, 2017"
output: html_document
---

```{r, echo = FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(TTR)

source("sl_utils.R")
```

The most basic type of alerting occurs when the current value of a metric exceeds a static threshold. However, alerting in this manner may only indicate a transient stress, so we may additionally require that the metric (either raw or smoothed) exceed the threshold for a certain amount of time. Such triggering rules can greatly reduce the incidence of false alarms, but are unsatisfactory in answering questions like "is the current load **normal** for this seasonally adjusted point in time". We are interested not only in cases where the key performance indicator (KPI) is significantly higher than expected, but also much lower than expected, as this condition may indicate loss of inputs to an otherwise healthy system (eg, on-line customers are not able to complete orders, credit-card transactions are lagging, denial of service attacks or network outages are affecting some number of remote terminals, etc.).

To answer such questions, we turn to dynamically computed thresholds. The classic example is "Bollinger Bands", where the upper and lower bounds are plotted as the moving average for the metric plus or minus two standard deviations. Given these bounding time-series, it is possible to generate alerts when the real-time trend crosses either boundary. In this article, we will demonstrate and compare various ways to generate these boundaries for use in an enterprise monitoring system like RTView. But first, as is customary in most data science endeavors, we examine the test data that will be used in these exercises.

## Data Exploration

The data used in this study was generated by a simulation of biometric screening requests at JFK International Airport. The simulated data is a good approximation of the actual weekly traffic seen at JFK, where the daily activity is similar on weekdays and usually much higher than on the weekends. Messages from iris scanners are queued by a Tibco EMS server until they can be processed for authentication by one or more EMS clients. The plot of weekly activity shows that authentication requests accumulate in the queue when the inbound message rate exceeds the max outbound rate, or in queueing theory terms, the arrival rate (lambda) exceeds the service rate (mu). Note that for this study, the service rate is constant (ie, an admistrator or automation does not scale the number of consumer processes in response to increasing load). Hence, the pending message volume does not drop until the inbound rate drops and we have a chance to work off the backlog. While messages are queued, the outbound rate plateaus at the service rate. After the queue is emptied, the outbound rate will follow the inbound rate as long as the inbound rate is less than the service rate. Finally, note that although this system is able to process all the requests received on a given day, the waiting time in the queue indicates an unacceptable delay for real-time authentication purposes. The service rate should be doubled to ensure adequate service.

In the following R script, the *getCacheHistory* function is provided by the included sl_utils R package. This function returns an R time-series (ts) object scaled in days since "1970-01-01" with a frequency of 96 fifteen-minute samples per day. This frequency is determined by the data compaction settings for each RTView cache. The default for the EmsQueues cache is to store data uncompacted for the most recent hour, compacted to five minute samples for the next two hours, and fifteen minute samples thereafter. If a query time span overlaps theses intervals, *getCacheHistory* will aggregate the higher-rate samples to return a valid R time series object with uniformly spaced samples (class ts) in the desired query time span.

```{r}
# query this dataserver for # queued messages in a certain queue
#dataserver <- "rtvdemos-163.sl.com"
#rtvQuery <- "simdata2_rtvquery"
dataserver <- "localhost:8068"
rtvQuery <- "emsmon_rtvquery"
cacheName <- "EmsQueues"
filterColumn <- "URL;name"
filterValue <- "tcp://VMIRIS1034:7222;SCAN-QUEUE"
columns <- "time_stamp;pendingMessageCount;inboundMessageRate;outboundMessageRate"

oneWeek <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue, dayOffset=7, ndays=7, cols=columns)

colnames(oneWeek) <- c("pending","inbound","outbound")
plot(oneWeek, main="Iris Scans Queued vs Producer/Consumer Rates for One Week ")
```

Note that the pending message curves on weekdays look quite similar, and appear to show little or no variance from day to day or week to week. Activity drops substantially on weekends. We can plot the pending messages for two weeks to compare daily activity. 

```{r}
#get ts data for the last two weeks
week1 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn,fval=filterValue,dayOffset=6,ndays=6,cols=columns)
week2 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn,fval=filterValue,dayOffset=13,ndays=6,cols=columns)

# set a common time range for both series
week1 <- ts(week1, start=start(week1)+c(7,0), end=end(week1)+c(7,0), frequency=frequency(week1))
week2 <- ts(week2, start=start(week1), end=end(week1), frequency=frequency(week1))

# plot pending messages for both weeks 
pmsgs <- ts.union(week1[,1],week2[,1], week1[,1]-week2[,1])
colnames(pmsgs) <- c("Last week","Preceding week","Difference")
plot(pmsgs, main="Difference between 2 weeks of Pending Messages")
```

The difference plot shows variance in the daily pending messages. On some days, the peak is randomly higher or lower, causing a delay in the time required by the consumers to empty the queue. This is seen in the difference plot as a high or low interval over the final hours of the day. Otherwise, one day looks quite a lot like another. We can confirm what we already know, that these two series are highly correlated, by a simple correlation test, which produces a correlation value close to one. In cases like this, it's easy to predict future behavior and set bounds on that behavior.

```{r}
# get ts data for same day (tomorrow) in the last two weeks.
# add a small offset to compensate for points lost in moving average.
day1 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=6,ndays=1,cols=columns)
day2 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=13,ndays=1,cols=columns)

# set a common time range (starting tomorrow) for both series
day1 <- ts(day1, start=start(day1)+c(7,0), end=end(day1)+c(7,0), frequency=frequency(day1))
day2 <- ts(day2, start=start(day1), end=end(day1), frequency=frequency(day1))

cor.test(day1[,1],day2[,1])
```


## Bollinger Bands

The data exploration revealed a high correlation in daily pending messages when the same day is compared week to week (which is not surprising, given that the data came from a simulation). This means that activity for tomorrow will be pretty much the same as a week ago. For example, we can easily predict future pending messages for next Monday as the average pending messages of two or more preceding Mondays.

John Bollinger developed tools for "Rational Analysis" in the early 1980's. His best known tool, Bollinger Bands, charts the moving average of a stock price against upper and lower bounds. When compared with the real-time stock price, boundary crossings suggest buy or sell points or other trading opportunities. By default, the current moving average and standard deviation are computed from the last 20 samples. The upper and lower price bounds are then computed as two standard deviations from the the moving average. Although technically incorrect (as discussed in the next section), this method of computing standard deviation recognizes that for many time-series variance (and hence, standard deviation) is actually a function of time, and so the distance of the bounds from the moving average may increase or decrease over the day. However, markets are subject to "bubbles", and prices may increase to unrealistic levels, constrained only by ability or willingness of market participants to pay. Modern computer systems operate under quite different capacity constraints. While it may be useful for exposing anomalies like unexpectedly large increases or decreases in the movement of some Key Performance Indicator, Bollingers method has no corrections for system non-linearities as the KPI trends higher and systems approach capacity limits.
```{r}
# get ts data for same day (tomorrow) in the last two weeks.
# add a small offset to compensate for points lost in moving average.
# By default, bollinger uses a 20 point single-sided moving average.
day1 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=6,secOffset=20*900,ndays=1,cols=columns)
day2 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=13,secOffset=20*900,ndays=1,cols=columns)

# set a common time range (starting tomorrow) for both series
day1 <- ts(day1, start=start(day1)+c(7,0), end=end(day1)+c(7,0), frequency=frequency(day1))
day2 <- ts(day2, start=start(day1), end=end(day1), frequency=frequency(day1))

# prediction for tomorrow: average of given days (optionally add more randomness)
nextDayEstimate <- (day1+day2)/2 #+ runif(length(day1), 10, 5000)
colnames(nextDayEstimate) <- c("pending","inbound","outbound")

# compute Bollinger bands out two std devs, & convert back to a time series
# (BBands function is from the TTR package)
bollinger <- ts(BBands(nextDayEstimate[,1], sd=2),start=start(nextDayEstimate),
                end=end(nextDayEstimate), frequency=frequency(nextDayEstimate),
                deltat=deltat(nextDayEstimate))

color.scale <- c("black", "grey", "black")
line.types <- c(1,3,1)
line.widths <- c(1,2,1)

plot(bollinger[,1:3], plot.type="single", main="Classic Bollinger Bands", col=color.scale, lty=line.types, lwd=line.widths, ylab="Pending Messages")
```


## Pseudo-Bollinger Bands

From a technical standpoint, a big problem with modeling the pending message time-series is that it's "non-stationary". That is, its statistics (mean and variance) vary with time. The classic Bollinger technique ignores this issue, and therefore computes bounds that are much too large. Fortunately, R comes to the rescue with a number of packaged methods to help "stationarize" your data. In this example, we remove the trend by a standard technique (differencing), calculate the standard deviation, and then add and subtract it from a smoothed prediction to arrive at a suitable high and low bounds for the KPI. The following code demonstrates this method by computing bounds for the day ahead.

```{r}
#  movingAvg calculates a moving average for the input vector x
#           using a window of size "n" (default 5).
#
movingAvg <- function(x,n=5){filter(x,rep(1/n,n), sides=2)}

#########################
#
#  bollingerThresholds executes a simple model to predict the behavior of a
#       given metric over the next 24 hours.
#
#       Given a time series of samples for a given metric on an averaged day,
#       this function smoothes the day with a moving average (default window 
#       is 5 samples, two sided). The Standard Deviation of the detrended data
#       is then added and subtracted to the moving average to create the 
#       upper and lower bounds for a Bollinger Band. 
#
bollingerThresholds <- function(avgDay, ma_window=5) {
    # align the time ranges so that we can average both series
    mavgDay <- na.omit(movingAvg(avgDay, n=ma_window))

    # ndiffs tells us how many differences we need to take in order to remove
    # the trend component from our data
    detrended_avg <- diff(avgDay,differences=ndiffs(avgDay))

    # create upper & lower bounds by biasing the smoothed average up and down
    # relative to the standard deviation of the stationarized smoothed data.
    sdDay <- sd(detrended_avg)
    upperBound <- mavgDay + 2*sdDay
    lowerBound <- pmax(mavgDay - 2*sdDay,0)     # dont allow series to go negative

    cbind(upperBound,lowerBound,mavgDay)   # return the predictions
}

# get ts data for same day (tomorrow) in the last two weeks.
# add a small offset to compensate for points lost in moving average.
# This example uses a 7 point double-sided moving average.
day1 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=6,secOffset=3*900,ndays=1,cols=columns)
day2 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=13,secOffset=3*900,ndays=1,cols=columns)

# set a common time range (starting tomorrow) for both series
day1 <- ts(day1, start=start(day1)+c(7,0), end=end(day1)+c(7,0), frequency=frequency(day1))
day2 <- ts(day2, start=start(day1), end=end(day1), frequency=frequency(day1))

# estimate as average of given days (optionally add more randomness)
nextDayEstimate <- (day1+day2)/2 #+ runif(length(day1), 10, 5000)
colnames(nextDayEstimate) <- c("pending","inbound","outbound")

# forecast the alert thresholds for tomorrow
thresholds <- bollingerThresholds(nextDayEstimate[,"pending"], ma_window=7)

color.scale <- c("grey", "blue", "grey")
line.types <- c(1,3,1)
line.widths <- c(1,1,1)

# plot the forecasted thresholds
plot(thresholds, plot.type="single", ylab="pending messages", main="Expected Threshold Bounds for Day Ahead", ylim=c(min(thresholds[,2]),max(thresholds[,1])))
lines(nextDayEstimate[,1],col="green",lty=1,lwd=3)

```

Since the variance for the simulation is small, the bounds are quite tight. To demonstrate that the math is correct, we'll increase the variance in the prediction and recompute the thresholds.

```{r}
#increase the variance
nextDayEstimate <- nextDayEstimate + runif(length(day1), 100, 5000)

# forecast the alert thresholds for tomorrow
thresholds <- bollingerThresholds(nextDayEstimate[,"pending"], ma_window=7)

# plot the forecasted thresholds
plot(thresholds, plot.type="single", ylab="pending messages", main="Expected Threshold Bounds, High Variance", ylim=c(min(thresholds[,2]),max(thresholds[,1])))
lines(nextDayEstimate[,1],col="green",lty=1,lwd=3)

```

Although the math behind this variation on Bollinger's method is perhaps saner, it still suffers from the same fundamental issue in that it ignores non-linear capacity constraints in real world systems. Bollinger Bands are sensitive to unexpected deviations from normalized behavior, and quite insensitive to level.


## Forecasting with Holt-Winters

```{r}
# start with data from last 7 days
week1 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue, dayOffset=7, ndays=7, cols="time_stamp;pendingMessageCount;inboundMessageRate")

# use same data for the preceding seven days
week2 <- ts(week1, start=start(week1)-c(7,0), end=end(week1)-c(7,0), frequency=frequency(week1))

# create a two week segment spanning the previous two weeks
forecastHistory <- ts(rbind(week2, week1), start=start(week2), end=end(week1), frequency=frequency(week1))

# fit the Holt-Winters model
hwFit <- HoltWinters(window(forecastHistory[,1],start(forecastHistory),end(forecastHistory)))
plot(hwFit,main="Holt-Winters Fit")
```

Generate a forecast for the day ahead.
```{r}
hwForecast <- forecast(hwFit, h=96)
plot(hwForecast, main="Holt-Winters Forecast", ylab="Pending Messages")
```

Compare forecast with data from 7 days earlier.
```{r}

expected <- window(forecastHistory[,1],end(forecastHistory)-c(7,0),end(forecastHistory)-c(6,0))
expected <- ts(expected, start=start(hwForecast$mean), end=end(hwForecast$mean), deltat=deltat(hwForecast), frequency=96)
result <- ts.union(expected, hwForecast$mean)
result <- cbind(result, ts(pmax(hwForecast$lower,0),deltat=deltat(result),start=start(result), frequency=96))
result <- cbind(result, ts(pmax(hwForecast$upper,0),deltat=deltat(result),start=start(result), frequency=96))

color.scale <- c("green", "blue", "grey", "black", "grey", "black")
line.types <- c(1,1,3,4,3,4)
line.widths <- c(3,3,1,1,1,1)
plot(result,plot.type="single",col=color.scale, lty=line.types, lwd=line.widths, main="Predicted vs Actual Behavior", ylab="Pending Messages")

legend.x <- start(hwForecast$mean)[1]
legend.y <- max(hwForecast$upper)
legend(legend.x,legend.y, legend=c("Actual","Predicted","80% Confidence","95% Confidence"), col=color.scale,lty=line.types,lwd=line.widths)
```


```{r}
result <- ts.union(expected, hwForecast$mean)

color.scale <- c("green", "blue")
line.types <- c(1,1)
line.widths <- c(3,3)
plot(result,plot.type="single",col=color.scale, lty=line.types, lwd=line.widths, main="Actual vs Predicted, without confidence intervals", ylab="Pending Messages")
```

## Forecasting with ARIMA


ARIMA (Auto-Regressive Integrated Moving Average)

```{r}

arimafit <- auto.arima(forecastHistory[,1], seasonal=TRUE)
arimaforecast <- forecast(arimafit, h=96)
plot(arimaforecast,main="ARIMA Forecast")
```

## Queueing Theory

In the previous sections, we based predictions about the future behavior of the "pending messages" metric solely on it's recent behavior. Queueing theory models the number of pending messages as a function of the arrival and service rates and the number of servers. We can use such models to predict future activity. However, this vast body of research mostly assumes long-term steady state conditions, where the mean arrival and service rates are constant, and the arrivals are exponentially distributed. Only a handful of papers deal with the more general issue of rates as a function of time. There are many practical problems of interest where the arrival rate varies throughout the day or during seasonal periods. For example, bakery sales may peak during store hours in the mid-morning, noon, and early evening hours, and be relatively flat between those times. In such cases, the arrival rate is clearly nonstationary. As previously shown in the data exploration section, the number of queued messages also has a "seasonal" component. In this case, the typical weekday volume, as shown below, is much higher than on Saturday or Sunday.


```{r nls-data}
# offset the query time-range so that data starts and ends at zero pending messages
dayOffset <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=6,secOffset=27*900,sides=0,ndays=1,cols=columns)

# set time range to use data as a prediction for tomorrow's metrics
dayOffset <- ts(dayOffset, start=start(dayOffset)+c(7,0), end=end(dayOffset)+c(7,0), frequency=frequency(dayOffset))
colnames(dayOffset) <- c("pending","inbound","outbound")
plot(dayOffset,ylab="Raw Data offset for Modeling")
```

Note that the number of queued messages is sensitive to the difference of the service and arrival rates; messages accumulate when the arrival rate exceeds the service rate. This introduces "memory" into the model, since the number of queued messages at the end of the next simulated interval is equal to number of previously queued messages plus the arrivals minus those consumed. This suggests that we could model this case using R's deSolve package for differential equations. Or more simply, we can estimate the arrival and service rates for the next interval, then directly calculate the expected number of queued messages via simulation. This leads to a simple threshold estimation based on recent metric history similar to Bollinger's method. Since we're only forecasting a single time step into the future, confidence is high that the actual value will lie within the computed bounds. This seems true as long as adequate history is available. Once the queue is emptied and our history window fills with zeroes, we'll need to develop a heuristic for estimating the next jump in queued messages.


## Non-Linear Regression

Queueing theory tells us that, long-term, the expected number of pending messages in a M/M/1 queue is 1/(mu - lambda), where mu is the service rate and lambda is the arrival rate, and the arrival rate is exponentially distributed. But, as discussed above, this idealized result simply doesnt hold for practical cases, where lambda is often time-dependent and nonstationary. For the simulated data used above, the pending messages curve has a parabolic shape, so for demonstration purposes, we'll model it as a second order polynomial. Note that the model should be a function of time, so we add a relative time parameter "t". 

```{r}

p0 = 4000
p1 = 5
p2 = 6
t = 1:length(dayOffset[,1]) * deltat(dayOffset[,1])
dayOffset <- cbind(dayOffset,ts(t,start=start(dayOffset[,1]),frequency=frequency(dayOffset[,1])))
colnames(dayOffset) <- c("pending","inbound","outbound","t")
nextDayFit <- nls(pending ~ p0+(t*(p1*outbound - p2*inbound))^2, as.data.frame(dayOffset), start=list(p0=p0,p1=p1,p2=p2))
nextDayFit
```

Using this model, we can calculate pending messages as a function of the inbound and outbound message rates as follows.

```{r}

plot(dayOffset[,1],lty=2,col="red",lwd=1,ylab="Pending Messages",main="p0+(t*(p1*outbound - p2*inbound))^2")
x <- index(dayOffset[,1])
lines(x, predict(nextDayFit), col="blue")
```

Not surprisingly, our guess at a formula performs rather poorly. A real parabola might fit the data better. The following formula models the pending messages as a function of time only.

```{r}

p0 = 65000
p1 = 5
tcenter = (frequency(dayOffset[,1])/2.0) *deltat(dayOffset[,1])
nextDayFit <- nls(pending ~ p0-p1*(t-tcenter)^2, as.data.frame(dayOffset), start=list(p0=p0,p1=p1))

plot(dayOffset[,1],lty=2,col="red",lwd=1,ylab="Pending Messages",main="p0-p1*(t-tcenter)^2")
lines(x, predict(nextDayFit), col="blue")
```

Regarding ease of implementation, with this approach you potentially need to calculate model parameters for each day of the week for this particular queue (not to mention the coding awkwardness of dealing with a relative time scale that resets each day). Piece-wise modeling (in which time is divided into a number of periods and a model is assigned to each) should be avoided due to concerns about implementation, maintenance, and execution efficiency. Besides, neither of the above models would be useful in a production setting where we are likely to see a large number of queues, each having distinct arrival and service profiles. Consider another simulated queue shown below. This example has a "somewhat" constant arrival rate (a random jitter is added at each hour) for the day; the queued message spikes occur randomly. Another example shows arrivals that peak at meal times. Hence, fitting parabolic models for every queue is clearly not a viable approach to setting alert thresholds for arbitrary queues.

```{r ECHO=FALSE}
# query this dataserver for # queued messages in a certain queue
filterValue <- "tcp://VMIRIS1061:7222;CHECK-QUEUE"
oneWeek <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue, dayOffset=7, ndays=7, cols=columns)

colnames(oneWeek) <- c("pending","inbound","outbound")
plot(oneWeek, main="Simulated Queue with Matched Arrival and Service Rates")
```

```{r ECHO=FALSE}
# query this dataserver for # queued messages in a certain queue
filterValue <- "tcp://VMIRIS1075:7222;REPORT-QUEUE"
oneWeek <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue, dayOffset=7, ndays=7, cols=columns)

colnames(oneWeek) <- c("pending","inbound","outbound")
plot(oneWeek, main="Simulated Queue with Peaks at Breakfast, Lunch, and Dinner")
```



## Logistic Regression

The previous modeling techniques estimated future activity and provided bounds on that activity for use as alert thresholds. Logistic regression is an alternative approach that directly determines an outcome (system is either OK or not OK), so quantitative alert thresholds are unnecessary. Instead, an LR model would be bound to an RTView "discrete" alert.

## Forecasting via Neural Nets

TBD: train a neural net to predict and bound activity.

## Conclusion

We have surveyed a number of different approaches to modeling the metrics collected while monitoring software applications. The characteristics of each approach can be summarized as follows.

1. Forecasting based on recent behavior
2. Curve fitting
3. Simulation
4. Machine learning

Discuss requirements for real-time estimation of alert thresholds.
