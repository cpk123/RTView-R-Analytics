---
title: "Time-Varying Thresholds for Alert Generation"
date: "December 14, 2017"
output: html_document
---

```{r, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(TTR)

source("sl_utils.R")
# variables for the threshold forecast.


```

The most basic type of alerting occurs when the current value of a metric exceeds a static threshold. However, alerting in this manner may only indicate a transient stress, so we may additionally require that the metric (either raw or smoothed) exceed the threshold for a certain amount of time. Such triggering rules can greatly reduce the incidence of false alarms, but are unsatisfactory in answering questions like "is the current load normal for this seasonally adjusted point in time". We are interested not only in cases where the key performance indicator (KPI) is not only significantly higher than expected, but also much lower than expected, as this condition may indicate loss of inputs to an otherwise healthy system (eg, on-line customers are not able to complete orders, credit-card transactions are lagging, denial of service attacks or network outages are affecting some number of remote terminals, etc.).

To answer such questions, we turn to dynamically computed thresholds. The classic example is "Bollinger Bands", where the upper and lower bounds are plotted as the moving average for the metric plus or minus two standard deviations. Given these bounding time-series, it is possible to generate alerts when the real-time trend crosses either boundary. In this article, we will demonstrate and compare various ways to generate these boundaries for use in an enterprise monitoring system like RTView. To be useful, the bounds are estimated up to a day ahead of real-time.

## Data Exploration

The data used in this study was generated by a simulation of biometric screening requests at JFK International Airport. The simulated data is a good approximation of the actual weekly traffic seen at JFK, where the daily activity is similar for weekdays and usually much higher than on the weekends. In the following R script, *getCacheHistory* is provided by the included sl_utils R package. This function returns an R time-series (ts) object scaled in days since "1970-01-01". The frequency is 96 fifteen-minute samples per day. 

```{r}
# query this dataserver for # queued messages in a certain queue
dataserver <- "rtvdemos-163.sl.com"
rtvQuery <- "simdata2_rtvquery"
cacheName <- "EmsQueueTotalsByServer"
filterColumn <- "URL"
filterValue <- "tcp://VMIRIS1023:7222"
columns <- "time_stamp;pendingMessageCount;inboundMessageRate;outboundMessageRate"

oneWeek <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue, dayOffset=8, ndays=7, cols=columns)

colnames(oneWeek) <- c("pending","inbound","outbound")
plot(oneWeek, main="Messages Queued vs Producer/Consumer Rates for One Week ")
```

Note that the pending messages on weekdays look quite similar, and appear to show little or no variance from day to day or week to week. We can plot the pending messages for two weeks to compare daily activity. (Note that the actual number of days plotted below is less than 7 so that RTView queries will return consistent 15 minute samples from the configured two-week data compaction interval managed by the RTView historian.)

```{r}
#get ts data for the last two weeks
week1 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn,fval=filterValue,dayOffset=6,ndays=5,cols=columns)
week2 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn,fval=filterValue,dayOffset=13,ndays=5,cols=columns)

# set a common time range for both series
#week1 <- ts(week1, start=start(week1)+c(7,0), end=end(week1)+c(7,0), frequency=frequency(week1))
week2 <- ts(week2, start=start(week1), end=end(week1), frequency=frequency(week1))

# plot pending messages for both weeks 
pmsgs <- ts.union(week1[,1],week2[,1], week1[,1]-week2[,1])
colnames(pmsgs) <- c("Last week","Preceding week","Difference")
plot(pmsgs, main="Difference between 2 weeks of Pending Messages")
```

The difference plot shows variance in the daily pending messages. On some days, the peak is randomly higher or lower, causing a delay in the time required by the consumers to empty the queue. This is seen in the difference plot as a high or low interval over the final hours of the day. Otherwise, one day looks quite a lot like another. We can confirm what we already know, that these two series are highly correlated, by a simple correlation test, which produces a correlation value close to one. In cases like this, it's easy to predict future behavior and set bounds on that behavior.

```{r}
# get ts data for same day (tomorrow) in the last two weeks.
# add a small offset to compensate for points lost in moving average.
day1 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=6,ndays=1,cols=columns)
day2 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=13,ndays=1,cols=columns)

# set a common time range (starting tomorrow) for both series
day1 <- ts(day1, start=start(day1)+c(7,0), end=end(day1)+c(7,0), frequency=frequency(day1))
day2 <- ts(day2, start=start(day1), end=end(day1), frequency=frequency(day1))

cor.test(day1[,1],day2[,1])
```


## Bollinger Bands

The data exploration revealed a high correlation in daily pending messages when the same day is compared week to week (which is not surprising, given that the data came from a simulation). This means that activity for tomorrow will be pretty much the same as a week ago. For example, we can easily predict future pending messages for next Monday as the average pending messages of two or more preceding Mondays. Averaging over several days may improve the forecast if subtle trends are present.

John Bollinger developed tools for "Rational Analysis" in the early 1980's. His best known tool, Bollinger Bands, charts the moving average of a stock price against upper and lower bounds. When compared with the real-time stock price, boundary crossing suggest buy or sell points or other trading opportunities. By default, the current moving average and standard deviation are computed from the last 20 samples. The upper and lower price bounds are then computed as two standard deviations from the the moving average. Although technically incorrect (as discussed in the next section), this method of computing standard deviation recognizes that for many time-series variance (and hence, standard deviation) is actually a function of time, and so the distance of the bounds from the moving average may increase or decrease over the day. However, markets are subject to "bubbles", and prices may increase to unrealistic levels, constrained only by ability or willingness of market participants to pay. Modern computer systems operate under quite different capacity constraints. While it may be useful for exposing anomalies like unexpectedly large increases or decreases in the movement of some Key Performance Indicator, Bollingers method has no corrections for system non-linearities as the KPI trends higher and systems approach capacity limits.
```{r}
# get ts data for same day (tomorrow) in the last two weeks.
# add a small offset to compensate for points lost in moving average.
# By default, bollinger uses a 20 point single-sided moving average.
day1 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=6,secOffset=20*900,ndays=1,cols=columns)
day2 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=13,secOffset=20*900,ndays=1,cols=columns)

# set a common time range (starting tomorrow) for both series
day1 <- ts(day1, start=start(day1)+c(7,0), end=end(day1)+c(7,0), frequency=frequency(day1))
day2 <- ts(day2, start=start(day1), end=end(day1), frequency=frequency(day1))

# estimate as average of given days (optionally add more randomness)
nextDayEstimate <- (day1+day2)/2 #+ runif(length(day1), 10, 5000)
colnames(nextDayEstimate) <- c("pending","inbound","outbound")

# compute Bollinger bands out two std devs, & convert back to a time series
bollinger <- ts(BBands(nextDayEstimate[,1], sd=2),start=start(nextDayEstimate),
                end=end(nextDayEstimate), frequency=frequency(nextDayEstimate),
                deltat=deltat(nextDayEstimate))

color.scale <- c("black", "grey", "black")
line.types <- c(1,3,1)
line.widths <- c(1,2,1)

plot(bollinger[,1:3], plot.type="single", main="Classic Bollinger Bands", col=color.scale, lty=line.types, lwd=line.widths, ylab="Pending Messages")
```


## Pseudo-Bollinger Bands

From a technical standpoint, a big problem with modeling the pending message time-series is that it's "non-stationary". That is, its statistics (mean and variance) vary with time. The classic Bollinger technique ignores this issue, and therefore computes bounds that are much too large. Fortunately, R comes to the rescue with a number of packaged methods to help "stationarize" your data. In this example, we remove the trend by a standard technique (differencing), calculate the standard deviation, and then add and subtract it from a smoothed prediction to arrive at a suitable high and low bounds for the KPI. The following code demonstrates this method by computing bounds for the day ahead.

```{r}
#  movingAvg calculates a moving average for the input vector x
#           using a window of size "n" (default 5).
#
movingAvg <- function(x,n=5){filter(x,rep(1/n,n), sides=2)}

#########################
#
#  bollingerThresholds executes a simple model to predict the behavior of a
#       given metric over the next 24 hours.
#
#       Given a time series of samples for a given metric on an averaged day,
#       this function smoothes the day with a moving average (default window 
#       is 5 samples, two sided). The Standard Deviation of the detrended data
#       is then added and subtracted to the moving average to create the 
#       upper and lower bounds for a Bollinger Band. 
#
bollingerThresholds <- function(avgDay, ma_window=5) {
    # align the time ranges so that we can average both series
    mavgDay <- na.omit(movingAvg(avgDay, n=ma_window))

    # ndiffs tells us how many differences we need to take in order to remove
    # the trend component from our data
    detrended_avg <- diff(avgDay,differences=ndiffs(avgDay))

    # create upper & lower bounds by biasing the smoothed average up and down
    # relative to the standard deviation of the stationarized smoothed data.
    sdDay <- sd(detrended_avg)
    upperBound <- mavgDay + 2*sdDay
    lowerBound <- pmax(mavgDay - 2*sdDay,0)     # dont allow series to go negative

    cbind(upperBound,lowerBound,mavgDay)   # return the predictions
}

# get ts data for same day (tomorrow) in the last two weeks.
# add a small offset to compensate for points lost in moving average.
# This example uses a 7 point double-sided moving average.
day1 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=6,secOffset=3*900,ndays=1,cols=columns)
day2 <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=13,secOffset=3*900,ndays=1,cols=columns)

# set a common time range (starting tomorrow) for both series
day1 <- ts(day1, start=start(day1)+c(7,0), end=end(day1)+c(7,0), frequency=frequency(day1))
day2 <- ts(day2, start=start(day1), end=end(day1), frequency=frequency(day1))

# estimate as average of given days (optionally add more randomness)
nextDayEstimate <- (day1+day2)/2 #+ runif(length(day1), 10, 5000)
colnames(nextDayEstimate) <- c("pending","inbound","outbound")

# forecast the alert thresholds for tomorrow
thresholds <- bollingerThresholds(nextDayEstimate[,"pending"], ma_window=7)

# plot the forecasted thresholds
plot(thresholds[,1], ylab="pending messages", main="Expected Threshold Bounds for Day Ahead", ylim=c(min(thresholds[,2]),max(thresholds[,1])))
lines(thresholds[,2])
lines(thresholds[,3],col=3,lty=3)
lines(nextDayEstimate[,1],col=5,lty=1,lwd=3)

```

Although the math behind this variation on Bollinger's method is perhaps saner, it still suffers from the same fundamental issue in that it ignores non-linear capacity constraints in real world systems.


## Non-Linear Regression

```{r}
# offset the data in order to model it with a parbolic model
dayOffset <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue,dayOffset=6,secOffset=-19*900,sides=1,ndays=1,cols=columns)

# set a common time range (starting tomorrow) for both series
dayOffset <- ts(dayOffset, start=start(dayOffset)+c(7,0), end=end(dayOffset)+c(7,0), frequency=frequency(dayOffset))
colnames(dayOffset) <- c("pending","inbound","outbound")
plot(dayOffset,ylab="Raw Data offset for Modeling")
```

```{r}
p0 = .5
p1 = 1
p2 = .5
nextDayFit <- nls(pending ~ p0-(p1*inbound - p2*outbound)^2, as.data.frame(dayOffset), start=list(p0=p0,p1=p1,p2=p2))
x <- seq(1,96,1)
plot(predict(nextDayFit))
```


## Forecasting with Holt-Winters

```{r}
forecastHistory <- getCacheHistory(dataserver,cacheName, rtvQuery, fcol=filterColumn, fval=filterValue, dayOffset=12, ndays=10, cols="time_stamp;pendingMessageCount")
hwFit <- HoltWinters(window(forecastHistory,start(forecastHistory),end(forecastHistory)-c(1,0)))
plot(hwFit,main="Holt-Winters Fit")
```


```{r}
hwForecast <- forecast(hwFit, h=96)
plot(hwForecast, main="Holt-Winters Forecast", ylab="Pending Messages")
```

```{r}
result <- ts.union(window(forecastHistory,end(forecastHistory)-c(1,0),end(forecastHistory)), hwForecast$mean)
result <- cbind(result, ts(hwForecast$lower,deltat=deltat(result),start=start(result)))
result <- cbind(result, ts(hwForecast$upper,deltat=deltat(result),start=start(result)))

color.scale <- c("green", "blue", "grey", "black", "grey", "black")
line.types <- c(1,1,3,4,3,4)
line.widths <- c(3,3,1,1,1,1)
plot(result,plot.type="single",col=color.scale, lty=line.types, lwd=line.widths, main="Actual vs Predicted", ylab="Pending Messages")

legend.x <- start(hwForecast$mean)[1]
legend.y <- max(hwForecast$upper)
legend(legend.x,legend.y, legend=c("Actual","Predicted","80% Confidence","95% Confidence"), col=color.scale,lty=line.types,lwd=line.widths)
```


## Forecasting via Neural Nets
